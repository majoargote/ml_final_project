{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MIMIC-III Hospital Mortality Pipeline\n",
        "Fresh build aligned with the updated PRD. Crisp notes so future Majo knows why choices were made.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Game plan**\n",
        "- Load train/test + diagnoses metadata from `MIMIC III dataset HEF`\n",
        "- Clean high-missing vitals, add age, engineer diagnosis severity features with Bayesian smoothing\n",
        "- Preprocess: impute, one-hot encode, scale\n",
        "- Train/evaluate Logistic Regression, Random Forest, XGBoost (if available)\n",
        "- Fit final model and export submission CSV with probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_recall_curve\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    HAS_XGB = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reproducibility + paths\n",
        "RANDOM_STATE = 42\n",
        "DATA_DIR = Path(\"MIMIC III dataset HEF\")\n",
        "TRAIN_PATH = DATA_DIR / \"mimic_train_HEF.csv\"\n",
        "TEST_PATH = DATA_DIR / \"mimic_test_HEF.csv\"\n",
        "DIAGNOSES_PATH = DATA_DIR / \"extra_data\" / \"MIMIC_diagnoses.csv\"\n",
        "\n",
        "EDA = False  # flip to True for plots\n",
        "pd.set_option(\"display.max_columns\", None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load core data\n",
        "train_raw = pd.read_csv(TRAIN_PATH)\n",
        "test_raw = pd.read_csv(TEST_PATH)\n",
        "diagnoses_raw = pd.read_csv(DIAGNOSES_PATH)\n",
        "\n",
        "print(f\"train shape: {train_raw.shape}\")\n",
        "print(f\"test shape:  {test_raw.shape}\")\n",
        "print(f\"diagnoses shape: {diagnoses_raw.shape}\")\n",
        "train_raw.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick data audit\n",
        "Sanity-check that train/test align and spot high-missing columns before trimming.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_cols = set(train_raw.columns)\n",
        "test_cols = set(test_raw.columns)\n",
        "missing_in_test = train_cols - test_cols\n",
        "print(\"Columns present in train but missing in test:\", missing_in_test)\n",
        "\n",
        "train_raw.isna().mean().sort_values(ascending=False).head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop rows with extreme vital-sign missingness\n",
        "Rows with >=21 of 24 vital summaries missing add noise. We drop them before any modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "VITAL_COLS = [\n",
        "    \"HeartRate_Min\", \"HeartRate_Max\", \"HeartRate_Mean\",\n",
        "    \"SysBP_Min\", \"SysBP_Max\", \"SysBP_Mean\",\n",
        "    \"DiasBP_Min\", \"DiasBP_Max\", \"DiasBP_Mean\",\n",
        "    \"MeanBP_Min\", \"MeanBP_Max\", \"MeanBP_Mean\",\n",
        "    \"RespRate_Min\", \"RespRate_Max\", \"RespRate_Mean\",\n",
        "    \"TempC_Min\", \"TempC_Max\", \"TempC_Mean\",\n",
        "    \"SpO2_Min\", \"SpO2_Max\", \"SpO2_Mean\",\n",
        "    \"Glucose_Min\", \"Glucose_Max\", \"Glucose_Mean\",\n",
        "]\n",
        "\n",
        "def drop_sparse_vitals(df: pd.DataFrame, threshold: int = 21) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    missing_counts = df[VITAL_COLS].isna().sum(axis=1)\n",
        "    keep_mask = missing_counts < threshold\n",
        "    print(f\"Dropping {(~keep_mask).sum()} rows with >= {threshold} missing vital features\")\n",
        "    return df.loc[keep_mask].reset_index(drop=True)\n",
        "\n",
        "train_clean = drop_sparse_vitals(train_raw)\n",
        "test_clean = test_raw.copy()  # test has similar patterns but we do not drop rows there\n",
        "print(\"train_clean shape:\", train_clean.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Age feature\n",
        "Age at admission derived from DOB and ADMITTIME. Clipped to [0, 110] to handle de-identification caps.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas import to_datetime\n",
        "\n",
        "def add_age_at_admission(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for col in [\"DOB\", \"ADMITTIME\"]:\n",
        "        df[col] = to_datetime(df[col], errors=\"coerce\")\n",
        "    df[\"age_at_admission\"] = (df[\"ADMITTIME\"] - df[\"DOB\"]).dt.total_seconds() / (60 * 60 * 24 * 365.25)\n",
        "    df[\"age_at_admission\"] = df[\"age_at_admission\"].clip(lower=0, upper=110)\n",
        "    return df\n",
        "\n",
        "train_enriched = add_age_at_admission(train_clean)\n",
        "test_enriched = add_age_at_admission(test_clean)\n",
        "train_enriched[[\"age_at_admission\", \"HOSPITAL_EXPIRE_FLAG\"]].describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diagnosis severity features (Bayesian-smoothed)\n",
        "We build diagnosis-level mortality scores using only training data, then aggregate per stay.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_diagnosis_features(train_df: pd.DataFrame, diagnoses_df: pd.DataFrame, alpha: int = 10):\n",
        "    # Fit diagnosis severity map on training data and return augmented dataframe + state.\n",
        "    df = train_df.copy()\n",
        "    diag = diagnoses_df.copy()\n",
        "    diag[\"HADM_ID\"] = diag[\"HADM_ID\"].astype(int)\n",
        "    diag[\"SEQ_NUM\"] = diag[\"SEQ_NUM\"].astype(float)\n",
        "\n",
        "    merged = diag.merge(df[[\"hadm_id\", \"HOSPITAL_EXPIRE_FLAG\"]], left_on=\"HADM_ID\", right_on=\"hadm_id\", how=\"left\")\n",
        "    merged = merged.dropna(subset=[\"HOSPITAL_EXPIRE_FLAG\"])\n",
        "\n",
        "    overall_mortality = merged[\"HOSPITAL_EXPIRE_FLAG\"].mean()\n",
        "    by_code = merged.groupby(\"ICD9_CODE\")[\"HOSPITAL_EXPIRE_FLAG\"].agg([\"mean\", \"count\"])\n",
        "    by_code[\"severity\"] = (\n",
        "        by_code[\"count\"] * by_code[\"mean\"] + alpha * overall_mortality\n",
        "    ) / (by_code[\"count\"] + alpha)\n",
        "    severity_map = by_code[\"severity\"].to_dict()\n",
        "\n",
        "    merged[\"severity_score\"] = merged[\"ICD9_CODE\"].map(severity_map).fillna(overall_mortality)\n",
        "\n",
        "    agg = merged.groupby(\"HADM_ID\").agg(\n",
        "        diagnosis_count=(\"ICD9_CODE\", \"count\"),\n",
        "        avg_diagnosis_severity=(\"severity_score\", \"mean\"),\n",
        "        max_diagnosis_severity=(\"severity_score\", \"max\"),\n",
        "    )\n",
        "\n",
        "    primary = merged.loc[merged[\"SEQ_NUM\"] == 1, [\"HADM_ID\", \"severity_score\"]].rename(\n",
        "        columns={\"severity_score\": \"primary_diagnosis_severity\"}\n",
        "    )\n",
        "    agg = agg.merge(primary, on=\"HADM_ID\", how=\"left\")\n",
        "    agg[\"primary_diagnosis_severity\"] = agg[\"primary_diagnosis_severity\"].fillna(overall_mortality)\n",
        "\n",
        "    df = df.merge(agg, left_on=\"hadm_id\", right_on=\"HADM_ID\", how=\"left\")\n",
        "    df[\"diagnosis_count\"] = df[\"diagnosis_count\"].fillna(0)\n",
        "    for col in [\"avg_diagnosis_severity\", \"max_diagnosis_severity\", \"primary_diagnosis_severity\"]:\n",
        "        df[col] = df[col].fillna(overall_mortality)\n",
        "\n",
        "    state = {\n",
        "        \"severity_map\": severity_map,\n",
        "        \"overall_mortality\": overall_mortality,\n",
        "        \"alpha\": alpha,\n",
        "    }\n",
        "    return df.drop(columns=[\"HADM_ID\"], errors=\"ignore\"), state\n",
        "\n",
        "\n",
        "def apply_diagnosis_features(df: pd.DataFrame, diagnoses_df: pd.DataFrame, state: dict):\n",
        "    # Apply pre-fitted diagnosis severity map to new data.\n",
        "    df = df.copy()\n",
        "    diag = diagnoses_df.copy()\n",
        "    diag[\"HADM_ID\"] = diag[\"HADM_ID\"].astype(int)\n",
        "    diag[\"SEQ_NUM\"] = diag[\"SEQ_NUM\"] .astype(float)\n",
        "\n",
        "    diag[\"severity_score\"] = diag[\"ICD9_CODE\"].map(state[\"severity_map\"]).fillna(state[\"overall_mortality\"])\n",
        "\n",
        "    agg = diag.groupby(\"HADM_ID\").agg(\n",
        "        diagnosis_count=(\"ICD9_CODE\", \"count\"),\n",
        "        avg_diagnosis_severity=(\"severity_score\", \"mean\"),\n",
        "        max_diagnosis_severity=(\"severity_score\", \"max\"),\n",
        "    )\n",
        "\n",
        "    primary = diag.loc[diag[\"SEQ_NUM\"] == 1, [\"HADM_ID\", \"severity_score\"]].rename(\n",
        "        columns={\"severity_score\": \"primary_diagnosis_severity\"}\n",
        "    )\n",
        "    agg = agg.merge(primary, on=\"HADM_ID\", how=\"left\")\n",
        "    agg[\"primary_diagnosis_severity\"] = agg[\"primary_diagnosis_severity\"].fillna(state[\"overall_mortality\"])\n",
        "\n",
        "    df = df.merge(agg, left_on=\"hadm_id\", right_on=\"HADM_ID\", how=\"left\")\n",
        "    df[\"diagnosis_count\"] = df[\"diagnosis_count\"].fillna(0)\n",
        "    for col in [\"avg_diagnosis_severity\", \"max_diagnosis_severity\", \"primary_diagnosis_severity\"]:\n",
        "        df[col] = df[col].fillna(state[\"overall_mortality\"])\n",
        "\n",
        "    return df.drop(columns=[\"HADM_ID\"], errors=\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_diag, diag_state = fit_diagnosis_features(train_enriched, diagnoses_raw)\n",
        "print(\"Overall mortality used for smoothing:\", diag_state[\"overall_mortality\"])\n",
        "\n",
        "# Apply the same mapping to test data\n",
        "test_diag = apply_diagnosis_features(test_enriched, diagnoses_raw, diag_state)\n",
        "train_diag[[\"diagnosis_count\", \"avg_diagnosis_severity\", \"max_diagnosis_severity\", \"primary_diagnosis_severity\"]].describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing pipeline (impute -> encode -> scale)\n",
        "Fit on training data only; reuse state for test set to avoid leakage.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "target_col = \"HOSPITAL_EXPIRE_FLAG\"\n",
        "categorical_cols = [\n",
        "    \"GENDER\", \"ADMISSION_TYPE\", \"INSURANCE\", \"RELIGION\",\n",
        "    \"MARITAL_STATUS\", \"ETHNICITY\", \"FIRST_CAREUNIT\",\n",
        "]\n",
        "drop_cols = [\n",
        "    \"subject_id\", \"hadm_id\", \"icustay_id\",\n",
        "    \"DOB\", \"ADMITTIME\", \"DISCHTIME\", \"DOD\", \"DEATHTIME\", \"LOS\",\n",
        "    \"DIAGNOSIS\", \"ICD9_diagnosis\",\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_preprocessing_pipeline(df: pd.DataFrame, target_col: str):\n",
        "    df = df.copy()\n",
        "    y = df[target_col].astype(int)\n",
        "    X = df.drop(columns=[target_col])\n",
        "    X = X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
        "\n",
        "    cat_cols = [c for c in categorical_cols if c in X.columns]\n",
        "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
        "\n",
        "    num_transformer = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ])\n",
        "\n",
        "    cat_transformer = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", num_transformer, num_cols),\n",
        "            (\"cat\", cat_transformer, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "    )\n",
        "\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    feature_names = []\n",
        "    if len(cat_cols) > 0:\n",
        "        enc = preprocessor.named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
        "        feature_names.extend(enc.get_feature_names_out(cat_cols))\n",
        "    feature_names.extend(num_cols)\n",
        "\n",
        "    state = {\n",
        "        \"preprocessor\": preprocessor,\n",
        "        \"feature_names\": feature_names,\n",
        "        \"cat_cols\": cat_cols,\n",
        "        \"num_cols\": num_cols,\n",
        "    }\n",
        "    return X_processed, y, state\n",
        "\n",
        "\n",
        "def apply_preprocessing_pipeline(df: pd.DataFrame, state: dict):\n",
        "    X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
        "    preprocessor = state[\"preprocessor\"]\n",
        "    return preprocessor.transform(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, y_train, preprocess_state = fit_preprocessing_pipeline(train_diag, target_col)\n",
        "print(\"Processed train shape:\", X_train.shape)\n",
        "print(\"Positive rate:\", y_train.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline models and cross-validation\n",
        "ROC-AUC is the primary metric; PR-AUC is a good secondary for the 88/12 split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_models_cv(models: dict, X, y, cv_splits: int = 5):\n",
        "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        auc_scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
        "        pr_scores = cross_val_score(model, X, y, cv=cv, scoring=\"average_precision\", n_jobs=-1)\n",
        "        results[name] = {\n",
        "            \"roc_auc_mean\": auc_scores.mean(),\n",
        "            \"roc_auc_std\": auc_scores.std(),\n",
        "            \"pr_auc_mean\": pr_scores.mean(),\n",
        "            \"pr_auc_std\": pr_scores.std(),\n",
        "        }\n",
        "    return pd.DataFrame(results).T.sort_values(by=\"roc_auc_mean\", ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imbalance_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "models = {\n",
        "    \"log_reg\": LogisticRegression(\n",
        "        max_iter=500,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "    ),\n",
        "    \"random_forest\": RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=None,\n",
        "        min_samples_leaf=2,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "    ),\n",
        "}\n",
        "\n",
        "if HAS_XGB:\n",
        "    models[\"xgboost\"] = XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"auc\",\n",
        "        scale_pos_weight=float(imbalance_weight),\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "else:\n",
        "    print(\"xgboost not installed in this env. Install if you want that model: pip install xgboost\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cv_results = evaluate_models_cv(models, X_train, y_train)\n",
        "cv_results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: quick XGBoost grid search\n",
        "Flip `RUN_GRIDSEARCH` to True once baseline results are known.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "RUN_GRIDSEARCH = False\n",
        "if RUN_GRIDSEARCH and HAS_XGB:\n",
        "    param_grid = {\n",
        "        \"n_estimators\": [150, 250, 300],\n",
        "        \"max_depth\": [3, 5, 7],\n",
        "        \"learning_rate\": [0.03, 0.05, 0.1],\n",
        "        \"subsample\": [0.8, 1.0],\n",
        "        \"colsample_bytree\": [0.8, 1.0],\n",
        "    }\n",
        "    xgb = models[\"xgboost\"]\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "    grid = GridSearchCV(\n",
        "        estimator=xgb,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "    print(\"Best ROC-AUC:\", grid.best_score_)\n",
        "    best_estimator = grid.best_estimator_\n",
        "else:\n",
        "    best_estimator = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final model fit on full training data\n",
        "Pick the winner from CV (or tuned XGB) and train on all processed data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if best_estimator is None:\n",
        "    best_model_name = cv_results.index[0]\n",
        "    best_model = clone(models[best_model_name])\n",
        "else:\n",
        "    best_model_name = \"xgboost_tuned\"\n",
        "    best_model = best_estimator\n",
        "\n",
        "best_model.fit(X_train, y_train)\n",
        "print(f\"Fitted {best_model_name} on full training set\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature importance peek\n",
        "Useful for the presentation. Logs top 20 features when available.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "feature_names = preprocess_state.get(\"feature_names\", [])\n",
        "\n",
        "if hasattr(best_model, \"feature_importances_\"):\n",
        "    importances = pd.Series(best_model.feature_importances_, index=feature_names)\n",
        "    display(importances.sort_values(ascending=False).head(20))\n",
        "elif hasattr(best_model, \"coef_\"):\n",
        "    coefs = pd.Series(best_model.coef_[0], index=feature_names)\n",
        "    display(coefs.sort_values(key=abs, ascending=False).head(20))\n",
        "else:\n",
        "    print(\"Model does not expose feature importances directly.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test-set preprocessing and submission file\n",
        "Applies the saved diagnosis + preprocessing states, then writes probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test = apply_preprocessing_pipeline(test_diag, preprocess_state)\n",
        "test_predictions = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"icustay_id\": test_diag[\"icustay_id\"],\n",
        "    \"prediction\": test_predictions,\n",
        "})\n",
        "submission.to_csv(\"argote_mariajose_CML_2025.csv\", index=False)\n",
        "\n",
        "print(submission.head())\n",
        "print(\"Saved submission -> argote_mariajose_CML_2025.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next steps (manual)\n",
        "- Run notebook top-to-bottom once models/libraries are installed\n",
        "- Log CV metrics in markdown for presentation\n",
        "- Push submission to leaderboard and record score\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}